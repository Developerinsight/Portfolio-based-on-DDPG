{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNR1TEG/mmmXRStdgxvVQBR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GBPzuX-nLtXy"},"outputs":[],"source":["!pip install gym\n","!pip install stable-baselines3 --quiet\n","!pip install 'shimmy>=0.2.1' --quiet\n","!pip install optuna --quiet\n","!pip install tslearn --quiet\n","!pip install pykrx --quiet\n","!pip install finance-datareader --quiet\n","!pip install chardet\n","!pip install seaborn\n","!pip install yfinance\n","!pip install openpyxl\n","!pip install optuna --quiet\n","!pip install pyfolio --quiet"]},{"cell_type":"code","source":["import pandas as pd\n","import chardet\n","import numpy as np\n","from collections import Counter\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import silhouette_score\n","from sklearn.decomposition import PCA\n","from tslearn.clustering import TimeSeriesKMeans\n","from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n","from tslearn.metrics import dtw, dtw_path\n","from tslearn.utils import to_time_series_dataset\n","\n","import networkx as nx\n","\n","import FinanceDataReader as fdr\n","from pykrx import stock\n","\n","import gym\n","from gym import spaces\n","import optuna\n","from stable_baselines3 import DDPG\n","from stable_baselines3.common.env_checker import check_env\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n","\n","from pykrx import stock\n","import yfinance as yf\n","\n","# import cv2\n","# from google.colab.patches import cv2_imshow\n","import warnings\n","\n","import gym\n","from gym import spaces\n","import optuna\n","from stable_baselines3 import DDPG\n","from stable_baselines3.common.env_checker import check_env\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise"],"metadata":{"id":"z_fjk9aHLx2y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt # 맷플롯립 import 하기\n","plt.rcParams['font.family'] = 'NanumBarunGothic' # 나눔바른고딕 적용하기\n","plt.rc(\"axes\", unicode_minus = False)"],"metadata":{"id":"FE2R1E-zLxzq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_korea = pd.read_excel('data/한국2.xlsx')\n","df_usa = pd.read_excel('data/미국2.xlsx')\n","\n","df_kospi = fdr.StockListing('KOSPI')\n","df_snp500 = fdr.StockListing('S&P500')\n","df_nasdaq = fdr.StockListing('NASDAQ')"],"metadata":{"id":"OernU8eTLxxr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_korea['Code'] = [i[1:] for i in df_korea['Code']]\n","df_korea.index = range(len(df_korea))"],"metadata":{"id":"K5jOXjmoLxvs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 한국 재무제표 종목 - KOSPI 상장 종목 매칭\n","kospi_list = list(df_kospi['Code'])\n","lst = []\n","for i in range(len(df_korea['Code'])):\n","  if df_korea.iloc[i, 0] not in kospi_list:\n","    lst.append(i)\n","\n","df_korea.drop(lst, axis=0, inplace=True)\n","\n","df_korea.head()"],"metadata":{"id":"qBVvnf8PLxt7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_korea.drop_duplicates(subset='Code', keep='first', inplace=True) # 중복 제거\n","df_korea"],"metadata":{"id":"Mu2CQ_maLxr8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_korea['Code'].unique())\n","df_usa.head()"],"metadata":{"id":"JibmUHo8LxqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_usa['Code'] = [i[:-3] for i in df_usa['Code']]\n","df_usa['Code'] = df_usa['Code'].str.strip()\n","df_usa.index = range(len(df_usa))\n","df_usa"],"metadata":{"id":"lmWIJSWzLxoJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 미국 재무제표 종목 - SnP500, NASDAQ 상장 종목 매칭\n","df_snp500['Symbol'] = df_snp500['Symbol'].str.strip()\n","df_nasdaq['Symbol'] = df_nasdaq['Symbol'].str.strip()\n","\n","usa_list = list(df_usa.index)\n","snp_list = list(df_snp500.index)\n","nasdaq_list = list(df_nasdaq.index)\n","\n","fdr_list = snp_list + nasdaq_list\n","fdr_list = set(fdr_list)\n","\n","lst = []\n","for i in usa_list:\n","    if i in usa_list:\n","        lst.append(i)\n","\n","len(lst)"],"metadata":{"id":"xvoy1tR3LxmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_usa = df_usa.loc[lst,:]\n","df_usa"],"metadata":{"id":"iVQLWCaoLxkD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["korea_columns = set(df_korea.columns)\n","usa_columns = set(df_usa.columns)\n","\n","if korea_columns == usa_columns:\n","    print(\"두 데이터프레임의 열이 동일합니다.\")\n","else:\n","    print(\"두 데이터프레임의 열이 다릅니다.\")\n","\n","    # 어떤 열이 다른지 확인\n","    diff_columns_korea = korea_columns - usa_columns\n","    diff_columns_usa = usa_columns - korea_columns\n","\n","    print(\"한국 데이터프레임에만 있는 열:\", diff_columns_korea) # 비유동부채비율, EBITDA/순이자비용\n","    print(\"미국 데이터프레임에만 있는 열:\", diff_columns_usa) # EBITDA/이자비용"],"metadata":{"id":"JVi3HBWELxh-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 미국-한국 union\n","columns_to_drop_korea = [col for col in df_korea.columns if '비유동부채비율' in col or 'EBITDA/순이자비용' in col]\n","df_korea = df_korea.drop(columns=columns_to_drop_korea)\n","\n","columns_to_drop_usa = [col for col in df_usa.columns if 'EBITDA/이자비용' in col]\n","df_usa = df_usa.drop(columns=columns_to_drop_usa)\n","\n","# 두 데이터프레임을 union (concatenate) 합치기\n","result_df = pd.concat([df_korea, df_usa], ignore_index=True)\n","\n","result_df.shape"],"metadata":{"id":"3nWHCe20Lxf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_melted_df(df, keyword):\n","    filtered = ['Code', 'Name'] + [col for col in df.columns if keyword in col]\n","    df1 = df[filtered]\n","\n","    # 컬럼명을 날짜 형태로 변경\n","    selected_cols = df1.columns[df1.columns.str.contains(keyword)]\n","    df1 = df1.copy()\n","\n","    start_date = pd.to_datetime('2010-01-01')\n","    date_columns = [start_date + pd.DateOffset(months=3 * i) for i in range(len(selected_cols))]\n","    date_column_mapping = dict(zip(selected_cols, date_columns))\n","\n","    df1.rename(columns=date_column_mapping, inplace=True)\n","\n","    date_column_mapping = {col: col.strftime('%Y-%m-%d') if col in date_columns else col for col in df1.columns}\n","    df1.rename(columns=date_column_mapping, inplace=True)\n","\n","    # 'Code'와 'Name'을 기준으로 데이터를 재구성\n","    melted_df = pd.melt(df1, id_vars=['Code', 'Name'], var_name='시점', value_name=keyword)\n","\n","    # '시점' 컬럼을 날짜 형식으로 변환\n","    melted_df['시점'] = pd.to_datetime(melted_df['시점'], errors='coerce')\n","\n","    return melted_df"],"metadata":{"id":"0qr77Xx6Lxdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 키워드 리스트 정의 (26개)\n","keywords = ['영업이익률', '세전계속사업이익률', '순이익률', '총포괄이익률', 'EBITDA마진율',\n","            'ROE', 'ROA', 'ROIC', '매출원가율', '총자산영업이익률',\n","            '자기자본영업이익률', '자본금영업이익률', '부채비율', '유동비율', '당좌비율',\n","            '유동부채비율', '자기자본비율', '이자보상배율', '순이자보상배율', '비유동비율',\n","            '차입금비율', '비유동적합률', '총자산회전율', '매출채권회전율', '재고자산회전율',\n","            '매입채무회전율']\n","\n","# 키워드별로 데이터프레임 생성\n","melted_dfs = [create_melted_df(result_df, keyword) for keyword in keywords]"],"metadata":{"id":"rT0TBVoeLxbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 행 수 147,774\n","df1_len = len(df1) // 4   # 영업이익률\n","df13_len = len(df13) // 2 # 부채비율\n","df14_len = len(df14) // 2 # 유동비율\n","df18_len = len(df18) // 2 # 이자보상배율\n","\n","df1 = df1.iloc[:df1_len]\n","df13 = df13.iloc[:df13_len]\n","df14 = df14.iloc[:df14_len]\n","df18 = df18.iloc[:df18_len]\n","\n","print(len(df1), ' ', len(df13), ' ', len(df14), ' ', len(df18))"],"metadata":{"id":"V6ovT3ehLxZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 6개의 데이터프레임을 melted_dfs 리스트에 저장한 후 merge\n","melted_dfs = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10,\n","              df11, df12, df13, df14, df15, df16, df17, df18, df19, df20,\n","              df21, df22, df23, df24, df25, df26]\n","\n","# 초기 조인 대상 데이터프레임을 melted_dfs[0]으로 설정\n","merged_df = melted_dfs[0]\n","\n","# 나머지 데이터프레임을 순회하면서 조인\n","for df in melted_dfs[1:]:\n","    merged_df = pd.merge(merged_df, df, on=['Code', 'Name', '시점'], how='inner')\n","\n","# 최종 데이터프레임 확인\n","merged_df"],"metadata":{"id":"-sIvG929LxXp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = merged_df.copy()\n","\n","# 날짜형식 변환\n","result['시점'] = pd.to_datetime(result['시점'], format='%Y-%m-%d')\n","result['시점']"],"metadata":{"id":"rmOvWmXuLxVr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 최초 nan 값 발생 시점 이전은 0으로 대체\n","# Term을 기준으로 그룹화하고, 각 그룹에서 처음 nan 값이 시작된 시점을 파악하여 그 시점 이전의 nan 값을 0으로 대체\n","result['시점'] = result.groupby('Code')['시점'].transform(lambda x: x.ffill().bfill())\n","result = result.fillna(0)\n","\n","result"],"metadata":{"id":"BssrMG1PLxTp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.to_csv('한국미국종목별_재무제표26개총합.csv', index=False)"],"metadata":{"id":"9Ux4BtaaLxRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_excel('data/한국미국종목별_재무제표26개총합2.xlsx')\n","df"],"metadata":{"id":"vuWsMVn4LxPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 블룸버그 공급망 데이터\n","bloom = pd.read_csv('./BigConDataset/NHIS_BDC_BLOOMBERG_SLY_CPE_LNK')\n","bloom.columns = ['회사코드', 'FIGI코드', '회사공식명',\n","                 '관계회사코드', '관계회사FIGI코드', '관계회사공식명',\n","                '관계형태', '관계회계연도', '관계기간금액', '통화', '관계원천',\n","                '관계시작일', '관계종료일', '수신일자']\n","bloom.head()"],"metadata":{"id":"kJ0zLLKKLxN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 공급을 많이 하는 회사 = CUSTOMER를 많이 보유한 회사\n","bloom2 = bloom[bloom['관계형태']=='CUSTOMER'] # supplier.\n","bloom2\n","# 회사가: UniTest, 관계회사:한국전력. 관계형태: Customer\n","# 한국전력이 UniTest의 고객이다~\n","\n"],"metadata":{"id":"xj_k5zJ1LxMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 최근순으로 정렬\n","bloom2.sort_values('관계회계연도', ascending=False)\n","# 중복 제거\n","bloom2 = bloom2.drop_duplicates(subset=['FIGI코드', '관계회사FIGI코드'], keep='first').reset_index(drop=True)\n","bloom2"],"metadata":{"id":"-w65GMsaLxH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bloom2.to_csv('data/블룸버그_고객관계데이터.csv', index=False)"],"metadata":{"id":"a274_eLeLxF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bloom2.to_csv('data/블룸버그_고객관계데이터.csv', index=False)"],"metadata":{"id":"JDUaUZ1jMWT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['FIGI Code'] = df['FIGI Code'].str.replace(' ', '')  # 'FIGI Code' 컬럼의 공백 제거\n","bloom['FIGI코드'] = bloom['FIGI코드'].str.replace(' ', '')  # 'FIGI코드' 컬럼의 공백 제거\n","bloom['관계회사FIGI코드'] = bloom['관계회사FIGI코드'].str.replace(' ', '')"],"metadata":{"id":"ZRXwq4LDMWQg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['시점'] = pd.to_datetime(df['시점'])\n","df2 = df.groupby('FIGI Code').apply(lambda x: x.loc[x['시점'].idxmax()]).reset_index(drop=True)\n","df2"],"metadata":{"id":"YwL-A8enMWOS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["G = nx.from_pandas_edgelist(bloom, 'FIGI코드', '관계회사FIGI코드', create_using=nx.DiGraph())\n","centrality = nx.degree_centrality(G) # 관계 기반으로 가중치 부여"],"metadata":{"id":"pIO8oPm2MWMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(20,10))\n","\n","# 중심성이 높은 상위 50개 노드 선택\n","top_50_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:50]\n","top_50_nodes = [node for node, centrality in top_50_nodes]\n","\n","# 상위 50개 노드로 구성된 서브그래프 생성\n","subgraph = G.subgraph(top_50_nodes)\n","\n","# 서브그래프 시각화\n","nx.draw(subgraph, with_labels=True)\n","plt.show()\n","\n","# K-means K개의 중심점 -> 중심성이 높은(고객이 많은) 회사를 중심으로\n","# 고객이 많은 회사끼리 묶인다??(X)\n","# 재무제표를 기반으로 클러스터링.\n","# 기존: 재무제표가지고 전체 재무제표의 패턴을 기반으로하는거였다면\n","# 현재: 중심성 높은 특정 A회사가 기준점이되는.(아마존과 재무제표비슷한클러스터.., 삼성과 비슷한클러스터..)\n","# 가정: A회사와 공급-고객 관계를 맺고 있는 B,C회사들이 A회사와 재무제표 흐름이 비슷하다면."],"metadata":{"id":"3EItS22NMWKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['weight'] = df['FIGI Code'].map(centrality)\n","df"],"metadata":{"id":"iuXXFb8cMWIs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2 = df.sort_values('weight', ascending=False)\n","df2 = df2.drop_duplicates(subset=['FIGI Code'], keep='first').reset_index(drop=True)\n","df2.head(50)"],"metadata":{"id":"fsy58rE6MWGk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['weight'] = df['weight'].fillna(0)\n","df.isna().sum()"],"metadata":{"id":"9rMrYVohMWEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["group = df.groupby(['Code', 'FIGI Code', 'Name']).mean()\n","group.head()"],"metadata":{"id":"6BIVfTwiMWCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = group.iloc[:, 0:-1].values  # 3번째 열 이후의 열이 시계열 데이터\n","\n","# 데이터 전처리: 시계열 데이터 스케일링\n","X = TimeSeriesScalerMeanVariance().fit_transform(X)"],"metadata":{"id":"YUtLb6jSMWAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3D 배열을 2D 배열로 변환\n","n_samples, n_timestamps, n_features = X.shape\n","X_2d = X.reshape(n_samples, -1)\n","\n","# 시도할 클러스터 개수 범위\n","min_clusters = 2\n","max_clusters = 10\n","\n","best_silhouette_score = -1\n","best_n_clusters = 0\n","\n","for n_clusters in range(min_clusters, max_clusters + 1):\n","    model = TimeSeriesKMeans(n_clusters=n_clusters, verbose=False, random_state=0)\n","    y_pred = model.fit_predict(X)\n","\n","    # 실루엣 점수 계산\n","    silhouette_avg = silhouette_score(X_2d, y_pred)\n","\n","    # 가장 높은 실루엣 점수를 갖는 클러스터 개수 찾기\n","    if silhouette_avg > best_silhouette_score:\n","        best_silhouette_score = silhouette_avg\n","        best_n_clusters = n_clusters\n","\n","print(f\"Best number of clusters: {best_n_clusters}\")\n","print(f\"Best silhouette score: {best_silhouette_score}\")"],"metadata":{"id":"K4tTksUWMV-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class WeightedDTW(TimeSeriesKMeans):\n","    def __init__(self, weights, *args, **kwargs):\n","        self.weights = weights\n","        super().__init__(*args, **kwargs)\n","\n","    def _transform_to_3D(self, X):\n","        X_3D = to_time_series_dataset(X)\n","        weights_3D = to_time_series_dataset(self.weights)\n","        return X_3D * weights_3D\n","\n","    def _dtw(self, X, X_bis, *args, **kwargs):\n","        X_3D = self._transform_to_3D(X)\n","        X_bis_3D = self._transform_to_3D(X_bis)\n","        return dtw(X_3D, X_bis_3D, *args, **kwargs)\n","\n","    def _dtw_path(self, X, X_bis, *args, **kwargs):\n","        X_3D = self._transform_to_3D(X)\n","        X_bis_3D = self._transform_to_3D(X_bis)\n","        return dtw_path(X_3D, X_bis_3D, *args, **kwargs)"],"metadata":{"id":"AmDtSvs9MV9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_clusters = best_n_clusters\n","weights = group['weight'].values\n","\n","model = WeightedDTW(weights=weights, n_clusters=n_clusters, verbose=True, random_state=0)\n","y_pred = model.fit_predict(X)"],"metadata":{"id":"qrtVNDNcMV7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 클러스터링 결과 출력\n","for cluster in range(n_clusters):\n","    cluster_samples = np.where(y_pred == cluster)[0]\n","    print(f\"Cluster {cluster}: {len(cluster_samples)}\")"],"metadata":{"id":"sh-ahn1MMV5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["group['Cluster'] = y_pred + 1 # 0,1,2 -> 1,2,3\n","group.reset_index(drop=False, inplace=True)\n","group.head()"],"metadata":{"id":"7_677ybPMnoy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.merge(group[['FIGI Code','Cluster']], on='FIGI Code', how='left')\n","df"],"metadata":{"id":"9mCGyKUSMnlM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,18))\n","# 클러스터별 특징 파악\n","temp = df.groupby('Cluster').mean(numeric_only=True)\n","cluster_mean = temp.transpose()\n","mean_table = cluster_mean.div(cluster_mean.max(axis=1), axis=0)\n","\n","plt.figure(figsize=(10,8))\n","annot_kws = {'fontsize':12}\n","vmin, vmax = 0 ,1\n","sns.heatmap(mean_table, annot=True, fmt='.2f',\n","           linewidths=0.1, annot_kws=annot_kws,\n","           cmap='RdYlBu_r', vmin=vmin, vmax=vmax)\n","plt.show()"],"metadata":{"id":"wWnLxxNwMnjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_cols = ['영업이익률', '세전계속사업이익률', '순이익률',\n","       '총포괄이익률', 'EBITDA마진율', 'ROE', 'ROA', 'ROIC', '매출원가율', '총자산영업이익률',\n","       '자기자본영업이익률', '자본금영업이익률', '부채비율', '유동비율', '당좌비율', '유동부채비율', '자기자본비율',\n","       '이자보상배율', '순이자보상배율', '비유동비율', '차입금비율', '비유동적합률', '총자산회전율', '매출채권회전율',\n","       '재고자산회전율', '매입채무회전율']\n","\n","def plot_clustered_line_chart(data, y_column):\n","    # 'Cluster'를 기준으로 그룹화하고 y_column 평균을 계산\n","    grouped_data = data.groupby(['Cluster', '시점'])[y_column].mean().reset_index()\n","\n","    # 각 클러스터에 대한 라인 차트 시각화\n","    plt.figure(figsize=(15, 6))\n","\n","    for cluster in grouped_data['Cluster'].unique():\n","        cluster_data = grouped_data[grouped_data['Cluster'] == cluster]\n","        plt.plot(cluster_data['시점'], cluster_data[y_column], '-o', label=f'Cluster {cluster}')\n","\n","    plt.xlabel('시점')\n","    plt.ylabel(f'{y_column} 평균')\n","    plt.xticks(rotation=45)  # x축 레이블을 45도 회전\n","    plt.legend()\n","    plt.title(f'클러스터별 {y_column} 평균 라인 차트')\n","    plt.grid(axis='y', linestyle='--')  # 가로 grid 줄 추가\n","\n","    plt.show()\n","\n","# 함수 호출\n","for y_column in num_cols:\n","    plot_clustered_line_chart(df, y_column)"],"metadata":{"id":"4VJDdfCkMnhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PCA 주성분분석, 차원축소\n","pca = PCA(n_components=15)\n","pca.fit(df[num_cols])\n","df_pca = pca.transform(group[num_cols])\n","\n","print('원본 데이터 형태: ', str(df.shape))\n","print('축소된 데이터 형태:', str(df_pca.shape))"],"metadata":{"id":"11bp1FnhMnfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('PCA 주성분 형태: ', pca.components_.shape)\n","print('PCA 주성분: ', pca.components_)"],"metadata":{"id":"ok1aZZ2dMnc_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 주성분의 원본 데이터에 대한 설명력 확인\n","print('각 주성분의 분산 비율: ', pca.explained_variance_ratio_)"],"metadata":{"id":"h5NxaN9PMna6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_components = range(1, min(len(group[num_cols].columns), len(group[num_cols])))\n","cumulative_variance = []\n","for n in num_components:\n","    pca = PCA(n_components=n)\n","    pca.fit(group[num_cols])\n","    cumulative_variance.append(np.sum(pca.explained_variance_ratio_))"],"metadata":{"id":"4CTSK1jkMnZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,3))\n","plt.plot(num_components, cumulative_variance, marker='o', linestyle='-')\n","plt.title('주성분 개수에 따른 누적 설명 분산')\n","plt.xlabel('주성분 개수')\n","plt.ylabel('누적 설명 분산')\n","plt.grid(True)\n","plt.show()\n","# 주성분 2개일때 데이터셋 99% 이상 설명"],"metadata":{"id":"9LqzSXtjMnXB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15,13))\n","plt.matshow(pca.components_, cmap='RdYlBu_r', fignum=1)\n","\n","plt.yticks([0,2])\n","plt.colorbar()\n","\n","plt.xticks(range(len(group[num_cols].columns)), group[num_cols].columns, rotation=80, ha='left')\n","\n","plt.xlabel('특성')\n","plt.ylabel('주성분')\n","\n","for i in range(len(pca.components_)):\n","    for j in range(len(group[num_cols].columns)):\n","        text = f'{pca.components_[i, j]:.2f}'\n","        plt.text(j, i, text, va='center', ha='center', color='black')\n","\n","## 주성분별 상관성 0.4 이상 변수\n","# 주성분1: 자본금영업이익률\n","# 주성분2: 영업이익률, 세전계속사업이익률, 순이익률, 총포괄이익률, EBITDA마진율"],"metadata":{"id":"clE5iFAmMnU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2 > 1> 4 > 7 > 3 > 6 > 5\n","df.groupby('Cluster')['weight'].mean()"],"metadata":{"id":"nOKeX6dKMnS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('data/종목별클러스터(블룸버그반영).csv')\n","data"],"metadata":{"id":"H1nTSIBpMnQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 'weight'를 기준으로 내림차순 정렬하여 상위 10개 기업을 선택하는 함수\n","def get_top_10_by_weight(group):\n","    return group.nlargest(10, 'weight')\n","\n","# 'Cluster'별로 상위 10개 기업을 선택하여 출력\n","top_10_by_cluster = data.groupby('Cluster').apply(get_top_10_by_weight)\n","top_10_by_cluster[:10]"],"metadata":{"id":"OMXJDXt1M8KZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 고객 데이터\n","cust = pd.read_csv('./BigConDataset/NHIS_BDC_NHDATA_CUS_TP_HLD_IEM')\n","cust.columns = ['기준일자', '종목코드', '고객구성대분류코드', '고객구성중분류코드', '보유종목분류기준코드', '보유기준종목코드', '보유종목순위기준']\n","cust"],"metadata":{"id":"pMswnK_EM8G1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 한국/미국 종목만 남기기\n","# 각 조건을 별도의 변수에 저장\n","cond1 = cust['종목코드'].str.startswith('A')\n","cond2 = cust['종목코드'].str.startswith('US')\n","cond3 = cust['보유기준종목코드'].str.startswith('A')\n","cond4 = cust['보유기준종목코드'].str.startswith('US')\n","\n","# 조건 결합\n","final_condition = (cond1 | cond2) & (cond3 | cond4)"],"metadata":{"id":"23vq1ryVM8FP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 최종 조건에 해당하지 않는 행의 인덱스를 찾아 제거\n","customer = cust[final_condition].copy()\n","\n","customer"],"metadata":{"id":"42lzZC8gM8DY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["customer.to_csv('data/개인투자자보유종목(한미종목).csv', index=False)"],"metadata":{"id":"VzJ2VgYBM8BK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["customer = pd.read_csv('data/개인투자자보유종목(한미종목).csv')\n","customer.head()"],"metadata":{"id":"nrPHa4DUM7_L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 연령대 대분류 고객만 선택\n","cat_cust = customer[customer['고객구성대분류코드']==2]\n","cat_cust"],"metadata":{"id":"D0k15KXGM79C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 고객 데이터 ISIN코드 미국(US)만 필터링\n","us_cust = cat_cust[cat_cust['종목코드'].str.contains('US')]\n","us_cust"],"metadata":{"id":"cZJ075_XM77J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 고객데이터 ISIN코드 중복 제거, 리스트에 담기\n","isin_lst = us_cust['종목코드'].unique().tolist()\n","len(isin_lst)"],"metadata":{"id":"oM0ck13fM75C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp = us_cust[us_cust['보유기준종목코드'].str.contains('US')]\n","temp"],"metadata":{"id":"3oVQMz2HM73G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp_lst = temp['보유기준종목코드'].unique().tolist()\n","len(temp_lst)"],"metadata":{"id":"7DmG9AVqM70-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 최종 종목 리스트 생성\n","final_lst = list(set(isin_lst + temp_lst))\n","len(final_lst)"],"metadata":{"id":"8LJpVNmXNJEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 해당 리스트 내 ISIN 코드 검색 -> TICKER명 크롤링\n","def fetch_ticker_values(isin):\n","    # The URL where the data is to be fetched from\n","    url = f\"https://www.morningstar.com/search?query={isin}\"\n","\n","    # Send a GET request to the URL\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        # Parse the HTML content of the page\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","\n","        # Find all span elements with class 'mdc-security-module__ticker'\n","        ticker_elements = soup.find_all(\"span\", class_=\"mdc-security-module__ticker\")\n","\n","        # Extracting text (ticker values) from each span element\n","        tickers = [element.get_text(strip=True) for element in ticker_elements]\n","\n","        return tickers[0] if tickers else None\n","    else:\n","        return None"],"metadata":{"id":"fKmSWs8FNJAu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ticker_dict = {}\n","for isin in tqdm(final_lst, desc=\"Fetching ticker values\"):\n","    ticker = fetch_ticker_values(isin)\n","    if ticker is not None:\n","        ticker_dict[isin] = ticker"],"metadata":{"id":"HFRF_pDZNI-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 티커코드 목록 저장\n","with open('tickers.txt', 'w') as f:\n","    for isin, ticker in ticker_dict.items():\n","        f.write(f\"{isin}: {ticker}\\n\")"],"metadata":{"id":"bNcDdFf3NI8k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ticker_dict = {}\n","\n","with open('tickers.txt', 'r') as file:\n","    lines = file.readlines()\n","    for line in lines:\n","        line = line.strip()\n","        if line:\n","            ticker, symbol = line.split(':')\n","            ticker_dict[ticker.strip()] = symbol.strip()"],"metadata":{"id":"2VPu4NSmNI6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# '종목코드' 컬럼의 ISIN코드를 해당하는 티커코드로 수정\n","us_cust['종목코드'] = us_cust['종목코드'].map(lambda x: ticker_dict.get(x, x))\n","us_cust['보유기준종목코드'] = us_cust['보유기준종목코드'].map(lambda x: ticker_dict.get(x, x))\n","\n","us_cust"],"metadata":{"id":"fmCbUkAiNI4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kr_cust = cat_cust[cat_cust['종목코드'].str.contains('A')]\n","kr_cust['보유기준종목코드'] = kr_cust['보유기준종목코드'].map(lambda x: ticker_dict.get(x, x))\n","\n","kr_cust"],"metadata":{"id":"pJDYN4CKNI29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_cust = pd.concat([us_cust, kr_cust], axis=0).drop_duplicates()\n","## 고객 데이터 완성"],"metadata":{"id":"CBGS_3WPNI05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_cust = pd.concat([us_cust, kr_cust], axis=0).drop_duplicates()\n","## 고객 데이터 완성"],"metadata":{"id":"i3dfmiJUNQrj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_cust.to_csv('data/연령대별고객보유종목데이터.csv', index=False)"],"metadata":{"id":"duiXcZJeNQn6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_cust = pd.read_csv('data/연령대별고객보유종목데이터.csv')\n","result_cust"],"metadata":{"id":"StT4K1dINQlz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 고객데이터와 재무제표 데이터 결합 (한국은 \"A\" + 재무제표데이터 Code / 미국은 그대로)\n","# 얘는 재무제표 데이터 + 클러스터 매핑된 데이터\n","\n","df = pd.read_excel('data/종목별클러스터(블룸버그반영).xlsx')\n","df_temp = df.copy()\n","df"],"metadata":{"id":"6qwnyP_FNQj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.sort_values('Code')\n","kr_df = df[:46037]\n","kr_df['Code'] = kr_df['Code'].apply(lambda x: 'A' + x)\n","us_df = df[46037:]\n","result_df = pd.concat([kr_df, us_df], axis=0)\n","## 재무제표 데이터 완성"],"metadata":{"id":"FHQ6klalNQiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df.to_csv('data/종목별클러스터(블룸버그반영).csv', index=False)\n","result_df"],"metadata":{"id":"y4z0Sl_CNQft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df = pd.read_csv('data/종목별클러스터(블룸버그반영).csv')\n","result_df\n"],"metadata":{"id":"NLWRFWT2NQds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_cust = pd.read_csv('data/연령대별고객보유종목데이터.csv')\n","result_cust"],"metadata":{"id":"Gy27QviSNQby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 연령대에 따른 고객 구분\n","cust1 = result_cust[result_cust['고객구성중분류코드'] == 21] # 0~29세\n","cust2 = result_cust[result_cust['고객구성중분류코드'] == 22] # 30~39세\n","cust3 = result_cust[result_cust['고객구성중분류코드'] == 23] # 40~49세\n","cust4 = result_cust[result_cust['고객구성중분류코드'] == 24] # 50~59세\n","cust5 = result_cust[result_cust['고객구성중분류코드'] == 25] # 60세~"],"metadata":{"id":"THwZI1YINQZs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_cust = result_cust.merge(result_df[['Code', 'Cluster']], left_on='종목코드', right_on='Code')\n","result_cust = result_cust.drop(columns='Code')\n","result_cust = result_cust.rename(columns={'Cluster': '종목코드 Cluster'})\n","\n","result_cust = result_cust.merge(result_df[['Code', 'Cluster']], left_on='보유기준종목코드', right_on='Code')\n","result_cust = result_cust.drop(columns='Code')\n","result_cust = result_cust.rename(columns={'Cluster': '보유기준종목코드 Cluster'})"],"metadata":{"id":"w6u5gamPNQXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_cust = result_cust.merge(result_df[['Code', 'Cluster']], left_on='종목코드', right_on='Code')\n","result_cust = result_cust.drop(columns='Code')\n","result_cust = result_cust.rename(columns={'Cluster': '종목코드 Cluster'})\n","\n","result_cust = result_cust.merge(result_df[['Code', 'Cluster']], left_on='보유기준종목코드', right_on='Code')\n","result_cust = result_cust.drop(columns='Code')\n","result_cust = result_cust.rename(columns={'Cluster': '보유기준종목코드 Cluster'})"],"metadata":{"id":"vIUInuz5NQWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 중복 제거 후 '종목코드 Cluster-보유기준종목코드 Cluster' 쌍의 count 계산\n","counts = cust2.drop_duplicates().groupby(['종목코드 Cluster', '보유기준종목코드 Cluster']).size().sort_values(ascending=True)\n","\n","# 막대 그래프 시각화\n","counts.plot(kind='barh')\n","plt.xlabel('종목코드 Cluster - 보유기준종목코드 Cluster')\n","plt.ylabel('Count')\n","plt.title('고객 연령대 30~39세')\n","plt.show()"],"metadata":{"id":"5axPnTstNQTz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 중복 제거 후 '종목코드 Cluster-보유기준종목코드 Cluster' 쌍의 count 계산\n","counts = cust3.drop_duplicates().groupby(['종목코드 Cluster', '보유기준종목코드 Cluster']).size().sort_values(ascending=True)\n","\n","# 막대 그래프 시각화\n","counts.plot(kind='barh')\n","plt.xlabel('종목코드 Cluster - 보유기준종목코드 Cluster')\n","plt.ylabel('Count')\n","plt.title('고객 연령대 40~49세')\n","plt.show()"],"metadata":{"id":"YrykzIxjNQRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 중복 제거 후 '종목코드 Cluster-보유기준종목코드 Cluster' 쌍의 count 계산\n","counts = cust4.drop_duplicates().groupby(['종목코드 Cluster', '보유기준종목코드 Cluster']).size().sort_values(ascending=True)\n","\n","# 막대 그래프 시각화\n","counts.plot(kind='barh')\n","plt.xlabel('종목코드 Cluster - 보유기준종목코드 Cluster')\n","plt.ylabel('Count')\n","plt.title('고객 연령대 50~59세')\n","plt.show()"],"metadata":{"id":"AwV9uWuYNQP5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 중복 제거 후 '종목코드 Cluster-보유기준종목코드 Cluster' 쌍의 count 계산\n","counts = cust5.drop_duplicates().groupby(['종목코드 Cluster', '보유기준종목코드 Cluster']).size().sort_values(ascending=True)\n","\n","# 막대 그래프 시각화\n","counts.plot(kind='barh')\n","plt.xlabel('종목코드 Cluster - 보유기준종목코드 Cluster')\n","plt.ylabel('Count')\n","plt.title('고객 연령대 60세 이상')\n","plt.show()"],"metadata":{"id":"tyXuhXLRNQN2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cust2 필터링\n","# '보유종목순위기준'이 1, 2, 3에 해당하는 행 추출\n","cust2 = cust2[cust2['보유종목순위기준'].isin([1, 2, 3])]\n","\n","# '종목코드'와 '보유기준종목코드'가 모두 중복되는 행 제거\n","cust2 = cust2.drop_duplicates(subset=['종목코드', '보유기준종목코드'])"],"metadata":{"id":"7sK5svn7NQMC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cust2 = cust2.merge(result_df[['Code', 'Cluster']], left_on='종목코드', right_on='Code')\n","cust2 = cust2.drop(columns='Code')\n","cust2 = cust2.rename(columns={'Cluster': '종목코드 Cluster'})\n","\n","cust2 = cust2.merge(result_df[['Code', 'Cluster']], left_on='보유기준종목코드', right_on='Code')\n","cust2 = cust2.drop(columns='Code')\n","cust2 = cust2.rename(columns={'Cluster': '보유기준종목코드 Cluster'})\n"],"metadata":{"id":"YFMzyY4QNQJ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ~29세 고객이 보유한 종목만 필터링\n","# '종목코드'와 '보유기준종목코드' unique 값 추출\n","unique_codes = cust2['종목코드'].unique().tolist() + cust2['보유기준종목코드'].unique().tolist()\n","unique_codes = list(set(unique_codes))\n","unique_codes = [item.strip() for item in unique_codes]\n","unique_codes[:5]\n"],"metadata":{"id":"YC0AbO6VNQIC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 'df'에서 'Code'가 unique_codes에 포함되는 행만 남기기\n","cust2_df = result_df[result_df['Code'].isin(unique_codes)]\n","cust2_df"],"metadata":{"id":"Ol7MfwJCNiMb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cust2_df_cluster5 = cust2_df[cust2_df['Cluster']==5]\n","cust2_df_cluster2 = cust2_df[cust2_df['Cluster']==2]\n","cust2_df_cluster1 = cust2_df[cust2_df['Cluster']==1]"],"metadata":{"id":"MgggO3SyNiK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cust2_df_cluster5 = cust2_df_cluster5.iloc[:, 1:].reset_index(drop=True)\n","cust2_df_cluster2 = cust2_df_cluster2.iloc[:, 1:].reset_index(drop=True)\n","cust2_df_cluster1 = cust2_df_cluster1.iloc[:, 1:].reset_index(drop=True)"],"metadata":{"id":"hn0A73QaNiJm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cust2_df_cluster5.to_csv('data/30-39세_고객_클러스터5번_보유종목.csv', index=False)\n","cust2_df_cluster2.to_csv('data/30-39세_고객_클러스터2번_보유종목.csv', index=False)\n","cust2_df_cluster1.to_csv('data/30-39세_고객_클러스터1번_보유종목.csv', index=False)"],"metadata":{"id":"RdsbIow4NiIL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 3. DDPG 강화학습\n","\n","- 고객군마다 해당되는 대표 클러스터별로 DDPG 강화학습 모델 구축\n","- 강화학습 모델은 종목 등락률로 학습, 샤프지수로 평가. 결과값으로 종목별 투자 시그널 제시, 효율적 투자선/샤프지수 포트폴리오 시각화\n","- 몬테카를로 시뮬레이션 추가하여 강화학습 모델 개선을 위한 파라미터 설정, 시장의 변화에 대응할 수 있는 인사이트를 도출\n","- 고객 구분(자산규모)에 따른 클러스터별 투자 시그널 on인 종목들 결과 종합, 종목의 특성을 확인하여, 고객들의 권장 투자 패턴 도출."],"metadata":{"id":"TjefVMzQNiG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('data/30-39세_고객_클러스터5번_보유종목.csv')\n","df"],"metadata":{"id":"KdJ2-E-sNiFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split_korea_us(tickers):\n","    korea = []\n","    usa = []\n","\n","    # 티커를 검사하여 적절한 리스트에 추가\n","    for ticker in tickers:\n","        if ticker[1:].isdigit():\n","            korea.append(ticker)\n","        else:\n","            usa.append(ticker)\n","    print(\"korea:\", len(korea))\n","    print(\"usa:\", len(usa))\n","\n","    return korea, usa"],"metadata":{"id":"YEmZc0bvNiDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tickers = list(df['Code'].unique())\n","korea, usa = split_korea_us(tickers)"],"metadata":{"id":"YGoNxsNcNiCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","from dateutil.relativedelta import relativedelta\n","\n","# 현재 날짜와 시간을 얻음\n","current_date = datetime.now()\n","\n","# 3년 전 날짜 계산 <-  일관되게 수익을 내고 위험을 관리하는 종목 선정 위해\n","years_ago = current_date - relativedelta(years=3)\n","\n","# 형식에 맞게 날짜를 문자열로 변환\n","start = years_ago.strftime('%Y-%m-%d')\n","\n","# 현재 날짜를 문자열로 변환\n","end = current_date.strftime('%Y-%m-%d')\n"],"metadata":{"id":"2rdsEsOXNiBE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def us_sharpe_ratio(usa, start):\n","    data = yf.download(usa, start=start)\n","    data.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis=1, inplace=True)\n","    data = data.droplevel(0,axis=1)\n","    rets = data.pct_change().fillna(0)\n","    sharpe_ratio = (rets.mean() * np.sqrt(252)) / rets.std()\n","\n","    return sharpe_ratio\n","\n","sharpe_ratio = us_sharpe_ratio(usa, start)"],"metadata":{"id":"_w12HPzUNh_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def korea_sharpe_ratio(korea, start, end):\n","    # 각 종목별 데이터를 저장할 빈 딕셔너리 생성\n","    data_dict = {}\n","\n","    # 각 종목별로 데이터를 가져와 딕셔너리에 저장\n","    for ticker in korea:\n","        data_dict[ticker[1:]] = stock.get_market_ohlcv_by_date(start,end,ticker[1:])\n","    results = {}\n","    for ticker, df in data_dict.items():\n","        results[ticker] = data_dict[ticker]['종가']\n","    df = pd.DataFrame(results)\n","\n","    rets = df.pct_change().fillna(0)\n","    sharpe_ratio2 = (rets.mean() * np.sqrt(252)) / rets.std()\n","\n","    return sharpe_ratio2\n","\n","sharpe_ratio2 = korea_sharpe_ratio(korea, start, end)"],"metadata":{"id":"kCglDoQcNh90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_total = pd.concat([sharpe_ratio, sharpe_ratio2])\n","df_total = df_total.sort_values(ascending=False)\n","df_total = df_total.sort_values(ascending=False)\n","df_cut = df_total[df_total>=0.5]"],"metadata":{"id":"SyUTXg5SNh6o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tickers = df_cut.index.unique()\n","korea, usa = split_korea_us(tickers)"],"metadata":{"id":"UcwAkESeNh5I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### from datetime import datetime\n","\n","# 현재 날짜와 시간을 얻음\n","current_date = datetime.now()\n","\n","end= current_date.strftime('%Y-%m-%d')\n","\n","from datetime import timedelta\n","\n","# 사용자 기간 설정\n","days = int(input())\n","\n","days_ago = current_date - timedelta(days=days)\n","\n","# 형식에 맞게 날짜를 문자열로 변환\n","start = days_ago.strftime('%Y-%m-%d')\n"],"metadata":{"id":"Yd6z9mrvNh3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def us_fluctuation_rate(usa, start):\n","    data = yf.download(usa, start=start)\n","    data.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis=1, inplace=True)\n","    data = data.droplevel(0,axis=1)\n","    daterange = pd.date_range(start=start, end=end)\n","    df_stocks = pd.DataFrame(index=daterange)\n","    df = df_stocks.join(data).fillna(method='ffill')\n","    rets = df.pct_change().fillna(0)\n","    df = rets\n","\n","    df_stocks = pd.DataFrame()\n","    cols = list(df.columns)\n","\n","    for i in cols:\n","        a = pd.DataFrame(df[i].values, index = df.index, columns = ['등락률'])\n","        b = pd.DataFrame([i]*len(df.index), index = df.index, columns=['종목'])\n","        c = pd.concat([a,b], axis=1)\n","        df_stocks = pd.concat([df_stocks, c], axis = 0)\n","\n","    return df_stocks\n","\n","df_stocks = us_fluctuation_rate(usa, start)"],"metadata":{"id":"x2ZqfyQ-Nh12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def korea_fluctuation_rate(korea, start, end):\n","    # 각 종목별 데이터를 저장할 빈 딕셔너리 생성\n","    data_dict = {}\n","\n","    # 각 종목별로 데이터를 가져와 딕셔너리에 저장\n","    for ticker in korea:\n","        data_dict[ticker] = stock.get_market_ohlcv_by_date(start,end,ticker)\n","    results = {}\n","    for ticker, df in data_dict.items():\n","        results[ticker] = data_dict[ticker]['종가']\n","    df = pd.DataFrame(results)\n","    daterange = pd.date_range(start=start, end=end)\n","    df_stocks2 = pd.DataFrame(index=daterange)\n","    df = df_stocks2.join(df).fillna(method='ffill')\n","    rets = df.pct_change().fillna(0)\n","    df = rets\n","    df_stocks2 = pd.DataFrame()\n","    cols = list(df.columns)\n","\n","    for i in cols:\n","        a = pd.DataFrame(df[i].values, index = df.index, columns = ['등락률'])\n","        b = pd.DataFrame([i]*len(df.index), index = df.index, columns=['종목'])\n","        c = pd.concat([a,b], axis=1)\n","        df_stocks2 = pd.concat([df_stocks2, c], axis = 0)\n","\n","    return df_stocks2\n","\n","df_stocks2 = korea_fluctuation_rate(korea, start, end)"],"metadata":{"id":"xMsdtEvoNhze"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_total = pd.concat([df_stocks, df_stocks2], axis=0)\n","df_total.rename(columns={'종목':'티커'}, inplace=True)\n","df = df_total\n","df = df.reset_index(drop=False)\n","df.rename(columns={'index': '날짜'}, inplace=True)\n"],"metadata":{"id":"-Kdpw03yNhwU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train, test셋을 나누기 위해 종목 기준으로 8:2로 나눈다.\n","\n","def split_data_per_ticker(df, train_ratio=0.8):\n","    train_data = pd.DataFrame()\n","    test_data = pd.DataFrame()\n","\n","    for ticker in df['티커'].unique():\n","        ticker_data = df[df['티커'] == ticker]\n","\n","        split_index = int(len(ticker_data) * train_ratio)\n","        train_data = train_data.append(ticker_data[:split_index])\n","        test_data = test_data.append(ticker_data[split_index:])\n","\n","    return train_data, test_data\n","\n","# 데이터를 훈련 및 테스트 세트로 분할\n","df_train, df_test = split_data_per_ticker(df)\n","\n","# 결과 확인\n","print(\"Train set size:\", len(df_train))\n","print(\"Test set size:\", len(df_test))\n","print(len(df_train['티커'].unique()))\n","print(len(df_test['티커'].unique()))\n"],"metadata":{"id":"aeswNjYhNhti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from stable_baselines3 import DDPG\n","from stable_baselines3.common.env_checker import check_env\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","\n","# 1. StockTradingEnv: 주식 트레이딩 환경 정의\n","class StockTradingEnv(gym.Env):\n","    def __init__(self, df_train):\n","        super(StockTradingEnv, self).__init__()\n","\n","        self.df = df_train\n","        self.current_step = 0\n","        self.portfolio_return_history = []\n","\n","        # Action space: Proportions for each stock (Continuous action space)\n","        self.action_space = spaces.Box(low=0, high=1, shape=(len(df_train['티커'].unique()),))\n","\n","        # State space: '등락률' for each stock\n","        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(len(df_train['티커'].unique()),))\n","\n","    def reset(self):\n","        self.current_step = 0\n","        #print(\"Resetting environment. Initial state:\", self._next_observation())\n","        self.portfolio_return_history = []\n","        self.df.reset_index(drop=True, inplace=True)\n","\n","        return self._next_observation()\n","\n","    def _next_observation(self):\n","\n","        obs = self.df.loc[self.current_step, '등락률']\n","        # If obs is not a Series (i.e., it's a scalar), make it into an array\n","        if not isinstance(obs, pd.Series):\n","            obs = np.array([obs])\n","        else:\n","            obs = obs.values\n","        return obs\n","\n","\n","    def step(self, action):\n","        # Ensure actions sum to 1 to represent allocation of capital between stocks\n","        action = action / np.sum(action)\n","\n","        # Get the stock returns for the next day\n","        next_day_returns = self.df.loc[self.current_step, '등락률']\n","\n","        # Calculate the portfolio return\n","        portfolio_return = np.dot(action, next_day_returns)\n","        self.portfolio_return_history.append(portfolio_return)\n","\n","        # Calculate the reward using the Sharpe Ratio\n","        expected_return = np.mean(self.portfolio_return_history)\n","        risk_free_rate = 0.01  # for example, a 1% risk-free rate\n","        std_return = np.std(self.portfolio_return_history)\n","        if std_return == 0:  # to avoid division by zero\n","            sharpe_ratio = 0\n","        else:\n","            sharpe_ratio = (expected_return - risk_free_rate) / std_return\n","\n","        reward = sharpe_ratio\n","\n","        # Move to the next day\n","        self.current_step += 1\n","\n","        # Get the new observation\n","        obs = self._next_observation()\n","\n","        # Check if we're done\n","        done = self.current_step >= len(self.df) - 1\n","\n","        return obs, reward, done, {}\n","\n","# 주식 데이터(df)는 이전과 동일하게 정의합니다.\n","\n","from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","class CustomNetwork(BaseFeaturesExtractor):\n","    def __init__(self, observation_space, features_dim=64):\n","        super(CustomNetwork, self).__init__(observation_space, features_dim)\n","        self.net = nn.Sequential(\n","            nn.Linear(observation_space.shape[0], 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),  # 50% 드롭아웃\n","            nn.Linear(64, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.5)\n","        )\n","\n","    def forward(self, observations):\n","        return self.net(observations)\n","\n","# 정책 네트워크의 구조 및 옵티마이저 설정\n","policy_kwargs = dict(\n","    features_extractor_class=CustomNetwork,\n","    features_extractor_kwargs=dict(features_dim=64),\n","    optimizer_class=torch.optim.Adam,\n","    optimizer_kwargs=dict(weight_decay=0.01)  # 가중치 감쇠 적용\n",")\n","\n","\n","\n","# 2. objective: optuna의 목표함수 정의\n","def objective(trial):\n","    gamma = trial.suggest_float('gamma', 0.9, 0.9999)\n","    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n","    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256])\n","\n","    env = DummyVecEnv([lambda: StockTradingEnv(df_train)])  # df는 주식 데이터의 데이터프레임입니다.\n","    model = DDPG('MlpPolicy', env, gamma=gamma, learning_rate=learning_rate, verbose=1, tensorboard_log=\"./tensorboard_logs\",  policy_kwargs=policy_kwargs)\n","    model.learn(total_timesteps=20000)\n","\n","    rewards = []\n","    obs = env.reset()\n","    for _ in range(1):  # 예: 1일 동안의 트레이딩을 시뮬레이션합니다.\n","        action, _ = model.predict(obs)\n","        obs, reward, done, _ = env.step(action)\n","        rewards.append(reward)\n","\n","    # 1일 동안의 보상의 평균을 반환합니다.\n","    avg_reward = np.mean(rewards)\n","    return avg_reward\n","\n","\n","# optuna를 사용하여 하이퍼파라미터 튜닝을 시작합니다.\n","study = optuna.create_study(direction=\"maximize\")  # 보상을 최대화합니다.\n","study.optimize(objective, n_trials=3)  # 예: 30번의 시도로 최적의 하이퍼파라미터를 찾습니다.\n","\n","# 최적의 하이퍼파라미터를 출력합니다.\n","print(\"Number of finished trials: \", len(study.trials))\n","print(\"Best trial:\")\n","trial = study.best_trial\n","\n","print(\"  Value: \", trial.value)\n","print(\"  Params: \")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")\n"],"metadata":{"id":"bVZfsQJLNhqs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from stable_baselines3.common.callbacks import BaseCallback\n","\n","class PrintRewardCallback(BaseCallback):\n","    def __init__(self, check_freq: int, verbose=0):\n","        super(PrintRewardCallback, self).__init__(verbose)\n","        self.check_freq = check_freq\n","        self.rewards = []\n","\n","    def _on_step(self):\n","        # Check if ep_info_buffer is not empty\n","        if self.model.ep_info_buffer:\n","            self.rewards.append(self.model.ep_info_buffer[-1]['r'])  # Append the reward\n","\n","        if self.n_calls % self.check_freq == 0 and self.rewards:\n","            mean_reward = np.mean(self.rewards[-self.check_freq:])\n","            print(f\"Mean Reward: {mean_reward:.2f}\")\n","        return True\n"],"metadata":{"id":"XVWZCi7hNhoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_params = study.best_params\n","\n","env = DummyVecEnv([lambda: StockTradingEnv(df_train)])\n","model = DDPG('MlpPolicy', env,\n","                gamma=best_params[\"gamma\"],\n","                 learning_rate=best_params[\"learning_rate\"],\n","                 batch_size=best_params[\"batch_size\"],\n","                 verbose=1,\n","                 tensorboard_log=\"./tensorboard_logs\",\n","                 policy_kwargs=policy_kwargs)\n","\n","callback = PrintRewardCallback(check_freq=1000)\n","model.learn(total_timesteps=20000)"],"metadata":{"id":"wRmbHgVvNhlR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["obs = env.reset()\n","for _ in range(len(df_train)):\n","    action, _ = model.predict(obs)\n","    obs, reward, done, _ = env.step(action)\n","\n","action"],"metadata":{"id":"mN-4RHK6NhiK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","import pandas as pd\n","from gym import spaces\n","\n","# 테스트 환경 정의 (기존 환경과 동일한 구조를 가집니다)\n","class StockTradingTestEnv(gym.Env):\n","    def __init__(self, df_test):\n","        super(StockTradingTestEnv, self).__init__()\n","\n","        self.df = df_test\n","        self.current_step = 0\n","        self.portfolio_return_history = []\n","\n","        # Action space: Proportions for each stock (Continuous action space)\n","        self.action_space = spaces.Box(low=0, high=1, shape=(len(df_test['티커'].unique()),))\n","\n","        # State space: '등락률' for each stock\n","        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(len(df_test['티커'].unique()),))\n","\n","    def reset(self):\n","        self.current_step = 0\n","        #print(\"Resetting environment. Initial state:\", self._next_observation())\n","        self.portfolio_return_history = []\n","        self.df.reset_index(drop=True, inplace=True)\n","\n","        return self._next_observation()\n","\n","    def _next_observation(self):\n","\n","        obs = self.df.loc[self.current_step, '등락률']\n","        # If obs is not a Series (i.e., it's a scalar), make it into an array\n","        if not isinstance(obs, pd.Series):\n","            obs = np.array([obs])\n","        else:\n","            obs = obs.values\n","        return obs\n","\n","\n","    def step(self, action):\n","        # Ensure actions sum to 1 to represent allocation of capital between stocks\n","        action = action / np.sum(action)\n","\n","        # Get the stock returns for the next day\n","        next_day_returns = self.df.loc[self.current_step, '등락률']\n","\n","        # Calculate the portfolio return\n","        portfolio_return = np.dot(action, next_day_returns)\n","        self.portfolio_return_history.append(portfolio_return)\n","\n","        # Calculate the reward using the Sharpe Ratio\n","        expected_return = np.mean(self.portfolio_return_history)\n","        risk_free_rate = 0.01  # for example, a 1% risk-free rate\n","        std_return = np.std(self.portfolio_return_history)\n","        if std_return == 0:  # to avoid division by zero\n","            sharpe_ratio = 0\n","        else:\n","            sharpe_ratio = (expected_return - risk_free_rate) / std_return\n","\n","        reward = sharpe_ratio\n","\n","        # Move to the next day\n","        self.current_step += 1\n","\n","        # Get the new observation\n","        obs = self._next_observation()\n","\n","        # Check if we're done\n","        done = self.current_step >= len(self.df) - 1\n","\n","        return obs, reward, done, {}\n","\n","\n","def test_model(env, model, benchmark_returns):\n","    total_returns = []\n","    obs = env.reset()\n","\n","    unique_dates = df_test['날짜'].unique()  # 날짜별로 유니크하게 추출\n","\n","    for i in range(len(unique_dates)-1):\n","        next_date = unique_dates[i + 1]\n","\n","        action, _ = model.predict(obs)\n","        obs, _, done, _ = env.step(action)\n","\n","        # action을 Pandas Series로 변환\n","        action_series = pd.Series(action[0]/action[0].sum())\n","\n","        # 다음 날짜에 해당하는 모든 종목의 등락률을 가져옵니다.\n","        next_day_returns = df_test[df_test['날짜'] == next_date]['등락률'].values\n","        print(next_day_returns)\n","        # 매수 비율과 다음 날의 등락률을 곱하여 일일 포트폴리오 수익률 계산\n","        daily_portfolio_return = np.dot(action_series, next_day_returns)\n","\n","        # 수익률을 리스트에 추가합니다.\n","        total_returns.append(daily_portfolio_return)\n","\n","    # 모델의 평균 일일 수익률을 계산합니다.\n","    model_mean_return = np.mean(total_returns)\n","    benchmark_mean_return = np.mean(benchmark_returns)\n","\n","    print(f\"Model Mean Return: {model_mean_return * 100}%\")\n","    print(f\"Benchmark Mean Return: {benchmark_mean_return * 100}%\")\n","\n","    success_rate = model_mean_return > benchmark_mean_return\n","    print(f\"Model beats the benchmark: {success_rate}\")\n","\n","    return model_mean_return, benchmark_mean_return, success_rate\n","\n","\n","\n","# 벤치마크: MSCI-> DM(선진시장) / EM(신흥시장) -> 미국 종목이 많을 경우 DM, 한국 종목이 많을 경우 EM\n","\n","datetime_str = str(df_test['날짜'].unique()[0])\n","\n","# 문자열에서 날짜 부분만 추출 ('T' 문자 전까지)\n","date_str = datetime_str.split('T')[0]\n","\n","data = yf.download(\"URTH\", start=date_str) # EEM\n","data.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis=1, inplace=True)\n","rets = data.pct_change().fillna(0)\n","\n","benchmark_returns = rets['Adj Close']  # 벤치마크 지수의 일별 수익률\n","\n","\n","# 테스트 환경 생성\n","test_env = DummyVecEnv([lambda: StockTradingTestEnv(df_test)])\n","\n","# 모델 테스트\n","test_avg_reward, benchmark_avg_return, success_rate = test_model(test_env, model, benchmark_returns)\n"],"metadata":{"id":"1ikokGFUNhfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save(\"model/ddpgV5\")"],"metadata":{"id":"3d5YGNZZNhc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c4MH7bvOODFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_in_out = pd.read_csv('./BigConDataset/NHIS_BDC_NHDATA_IFW_OFW_RNK')\n","data_in_out.columns = ['유입유출구분코드', '기준일자', '종목코드', '유입유출기간코드', '유입유출종목코드', '유입유출순위']\n","data_in_out"],"metadata":{"id":"WRyw9jZ1OC5q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_names = pd.read_csv('./data/종목별클러스터(블룸버그반영).csv')\n","df_names"],"metadata":{"id":"NjAdtVT4OC39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["names_map = df_names.set_index('Code')['Name'].to_dict()"],"metadata":{"id":"1QSbROSgOC2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = data_in_out.copy()\n","df.head()"],"metadata":{"id":"Z5LzFSd_OC0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = './tickers.txt'\n","with open(file_path, 'r') as file:\n","    lines = file.readlines()\n","\n","ticker_dict = {}\n","for line in lines:\n","    # Assuming each line is in the format \"key: value\"\n","    parts = line.strip().split(':')\n","    if len(parts) == 2:\n","        key, value = parts\n","        ticker_dict[key.strip()] = value.strip()\n"],"metadata":{"id":"blrwWbY1OCtj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path2 = './tickers2.txt'\n","with open(file_path2, 'r') as file:\n","    lines = file.readlines()\n","\n","ticker_dict2 = {}\n","for line in lines:\n","    # Assuming each line is in the format \"key: value\"\n","    parts = line.strip().split(':')\n","    if len(parts) == 2:\n","        key, value = parts\n","        ticker_dict2[key.strip()] = value.strip()\n"],"metadata":{"id":"pSlE2RLmOCsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ticker_merged = dict(ticker_dict, **ticker_dict2)"],"metadata":{"id":"IgrB6ub9OCq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_merged = dict(names_map, **ticker_merged)"],"metadata":{"id":"PNkuVy79OCpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['종목코드'] = df['종목코드'].str.strip()\n","df['종목코드'] = df['종목코드'].str.replace('A', '')\n","df['유입유출종목코드'] = df['유입유출종목코드'].str.strip()\n","df['유입유출종목코드'] = df['유입유출종목코드'].str.replace('A', '')\n","\n","df['종목명'] = df['종목코드'].map(d4)\n","df['유입유출종목명'] = df['유입유출종목코드'].map(d4)"],"metadata":{"id":"aWvRNakfOCnR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dropna(inplace=True)\n","df.info()"],"metadata":{"id":"9PapgTTlONDK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cluster5 = pd.read_csv('./data/30-39세_고객_클러스터5번_보유종목.csv')\n","df_cluster5"],"metadata":{"id":"zt_a5BoiOM_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clusters = df_cluster5.Name.unique()\n","inflow_outflow_data = df"],"metadata":{"id":"nAVpj1IOOM9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inflow_outflow_data"],"metadata":{"id":"c2dyZUDqOM7e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cluster_inflow = inflow_outflow_data[(inflow_outflow_data['종목명'].isin(clusters)) & (inflow_outflow_data['유입유출구분코드'] == 1)]\n","cluster_outflow = inflow_outflow_data[(inflow_outflow_data['종목명'].isin(clusters)) & (inflow_outflow_data['유입유출구분코드'] == 2)]"],"metadata":{"id":"EaZRzT8eOM5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def adjust_portfolio_inflow(portfolio, inflow_data):\n","    for ticker in portfolio:\n","        if ticker in inflow_data['종목명'].values:\n","            inflow_rank = inflow_data[inflow_data['종목명'] == ticker]['유입유출순위'].iloc[0]\n","            portfolio[ticker]['weight'] += 1 / inflow_rank\n","    return portfolio\n"],"metadata":{"id":"gskAQSjIOM3r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def adjust_portfolio_outflow(portfolio, outflow_data, all_tickers):\n","    for ticker in portfolio:\n","        if ticker in outflow_data['종목명'].values:\n","            outflow_rank = outflow_data[outflow_data['종목명'] == ticker]['유입유출순위'].iloc[0]\n","            if outflow_rank < threshold:\n","                del portfolio[ticker]\n","            new_ticker = outflow_data[outflow_data['종목명'] == ticker]['유입유출종목명'].iloc[0]\n","            if new_ticker not in portfolio and new_ticker in all_tickers:\n","                portfolio[new_ticker] = {'weight': initial_weight}\n","    return portfolio\n"],"metadata":{"id":"f3JEWDtXOM1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["portfolio_tickers = clusters\n","\n","portfolio = {ticker: {'weight': 1/len(portfolio_tickers)} for ticker in portfolio_tickers}\n","all_tickers = set(inflow_outflow_data['종목명'].unique()) | set(inflow_outflow_data['유입유출종목명'].unique())\n","\n","# 유입 데이터를 기반으로 포트폴리오 비중 조정\n","inflow_data = inflow_outflow_data[inflow_outflow_data['유입유출구분코드'] == '01']\n","outflow_data = inflow_outflow_data[inflow_outflow_data['유입유출구분코드'] == '02']\n","\n","#portfolio = adjust_portfolio_inflow(portfolio, inflow_data)"],"metadata":{"id":"dk2FAfilOMxI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cluster_tickers = clusters"],"metadata":{"id":"09IBZQjUOMvB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reinforcement_portfolio_weights = action[0]"],"metadata":{"id":"Vkl264TsOMtP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reinforcement_portfolio_weights = [max(0, weight) for weight in reinforcement_portfolio_weights]\n","\n","total_weight = sum(reinforcement_portfolio_weights)\n","normalized_weights = [weight / total_weight for weight in reinforcement_portfolio_weights]\n","\n","sum(normalized_weights)\n"],"metadata":{"id":"P43b7ngmOMrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selected_tickers = list(cluster_tickers)[:333]\n","len(selected_tickers)"],"metadata":{"id":"tgEX0V-mOMpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 클러스터 종목 목록\n","cluster_tickers = selected_tickers\n","\n","# 강화학습으로부터 받은 포트폴리오 가중치 (배열로 표현)\n","reinforcement_portfolio_weights = normalized_weights\n","\n","# 종목과 인덱스 매핑\n","ticker_to_index = {ticker: index for index, ticker in enumerate(cluster_tickers)}\n","\n","# 제거 및 추가된 종목을 추적하기 위한 리스트\n","removed_tickers = []\n","added_tickers = []\n","\n","# 가중치 조정을 위한 팩터\n","adjustment_factor = 0.05  # 가중치 조정을 위한 팩터\n","outflow_threshold = 3     # 유출 데이터에서 종목을 제거하기 위한 순위 기준\n","\n","# 유입 및 유출 데이터를 기반으로 가중치를 조정하는 함수\n","def adjust_weights_by_inflow_outflow(rl_weights, inflow_data, outflow_data):\n","    global removed_tickers, added_tickers\n","\n","    # 유입 데이터에 따른 가중치 조정 및 종목 추가\n","    for _, row in inflow_data.iterrows():\n","        ticker = row['종목명']\n","        inflow_rank = row['유입유출순위']\n","        period_code = row['유입유출기간코드']\n","        # 기간 코드에 따른 가중치 조정 로직\n","        period_factor = 1 if period_code in [1, 2] else 2 if period_code == 3 else 3\n","\n","        if ticker in ticker_to_index:\n","            index = ticker_to_index[ticker]\n","            rl_weights[index] += adjustment_factor * period_factor / inflow_rank\n","\n","    # 유출 데이터에 따른 가중치 조정 및 종목 제거\n","    for _, row in outflow_data.iterrows():\n","        ticker = row['종목명']\n","        outflow_rank = row['유입유출순위']\n","        if ticker in ticker_to_index and outflow_rank < outflow_threshold:\n","            index = ticker_to_index[ticker]\n","            removed_tickers.append(ticker)\n","            rl_weights[index] = 0  # 가중치를 0으로 설정하여 종목 제거\n","\n","    # 가중치 정규화 (합계가 1이 되도록)\n","    total_weight = sum(rl_weights)\n","    rl_weights = [weight / total_weight for weight in rl_weights]\n","\n","    return rl_weights\n","\n","# 유입 및 유출 데이터\n","# inflow_data, outflow_data - 이전 예제에서 정의된 DataFrame 사용\n","\n","# 가중치 조정 실행\n","adjusted_portfolio_weights = adjust_weights_by_inflow_outflow(\n","    reinforcement_portfolio_weights,\n","    inflow_data,\n","    outflow_data\n",")\n","\n","# 결과 출력\n","print(\"조정된 포트폴리오 가중치: \", adjusted_portfolio_weights)\n","print(\"제거된 종목: \", removed_tickers)\n","print(\"새로 편입된 종목: \", added_tickers)\n"],"metadata":{"id":"zIOBZ8GuOMnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sBlbJK7uOMlO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_data = df_test\n","original_data"],"metadata":{"id":"_LIT4dOxOMjE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_data.reset_index(inplace=True)\n","original_data.rename(columns={'index':'date'}, inplace=True)\n","original_data.reset_index(inplace=True)\n"],"metadata":{"id":"MJx4-Tw-OMhQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pivoted_df = original_data.pivot(index='date', columns='티커', values='등락률')\n"],"metadata":{"id":"Lc2uygDeOMfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pyfolio as pf\n","import pandas as pd\n","import numpy as np\n","\n","# Assuming 'filled_pivoted_df' is your DataFrame and it has a date column\n","filled_pivoted_df = pivoted_df.apply(lambda col: col.fillna(col.mean()), axis=0)\n","\n","# Convert the index of your DataFrame to DateTime if it's not already\n","if not isinstance(filled_pivoted_df.index, pd.DatetimeIndex):\n","    filled_pivoted_df.index = pd.to_datetime(filled_pivoted_df.index)\n","\n","filled_pivoted_df = filled_pivoted_df.apply(lambda col: col.fillna(col.mean()), axis=0)\n","nan_info_after = filled_pivoted_df.isna().sum().sum()\n","print(filled_pivoted_df.head())\n","print(\"Remaining NaN values after filling:\", nan_info_after)\n","\n","# Calculate Portfolio Returns\n","n_assets = len(filled_pivoted_df.columns) # Assuming each column is an asset\n","portfolio_weights = n_assets * [1 / n_assets]\n","portfolio_returns = pd.Series(np.dot(portfolio_weights, filled_pivoted_df.T),\n","                              index=filled_pivoted_df.index)\n","\n","# Create Pyfolio Tear Sheet\n","pf.create_simple_tear_sheet(portfolio_returns)\n"],"metadata":{"id":"lIYzr7aKOMdV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N_PORTFOLIOS = 10 ** 5\n","N_DAYS = 252\n","RISKY_ASSETS = list(returns.columns.unique())\n","RISKY_ASSETS.sort()\n","START_DATE = str(returns.index[0]).split(' ')[0]\n","END_DATE = str(returns.index[-1]).split(' ')[0]\n","\n","n_assets = len(RISKY_ASSETS)"],"metadata":{"id":"lAI8wBPfOMbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.random.seed(42)\n","weights = np.random.random(size=(N_PORTFOLIOS, n_assets))\n","weights /=  np.sum(weights, axis=1)[:, np.newaxis]"],"metadata":{"id":"65i-Q8B3OMZf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["returns_df = filled_pivoted_df"],"metadata":{"id":"PA7czKiuOg1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avg_returns = returns_df.mean() * N_DAYS\n","cov_mat = returns_df.cov() * N_DAYS"],"metadata":{"id":"99s1uJjWOgzh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["portf_rtns = np.dot(weights, avg_returns)\n","\n","portf_vol = []\n","for i in range(0, len(weights)):\n","    portf_vol.append(np.sqrt(np.dot(weights[i].T,\n","                                    np.dot(cov_mat, weights[i]))))\n","portf_vol = np.array(portf_vol)\n","portf_sharpe_ratio = portf_rtns / portf_vol"],"metadata":{"id":"OBSSjJNFOgxt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["portf_results_df = pd.DataFrame({'returns': portf_rtns,\n","                                 'volatility': portf_vol,\n","                                 'sharpe_ratio': portf_sharpe_ratio})"],"metadata":{"id":"6REfqeMkOgv4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N_POINTS = 100\n","portf_vol_ef = []\n","indices_to_skip = []\n","\n","portf_rtns_ef = np.linspace(portf_results_df.returns.min(),\n","                            portf_results_df.returns.max(),\n","                            N_POINTS)\n","portf_rtns_ef = np.round(portf_rtns_ef, 2)\n","portf_rtns = np.round(portf_rtns, 2)\n","\n","for point_index in range(N_POINTS):\n","    if portf_rtns_ef[point_index] not in portf_rtns:\n","        indices_to_skip.append(point_index)\n","        continue\n","    matched_ind = np.where(portf_rtns == portf_rtns_ef[point_index])\n","    portf_vol_ef.append(np.min(portf_vol[matched_ind]))\n","\n","portf_rtns_ef = np.delete(portf_rtns_ef, indices_to_skip)"],"metadata":{"id":"7s5WsT6rOguS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#MARKS = ['o', 'X', 'd', '*']\n","\n","fig, ax = plt.subplots()\n","portf_results_df.plot(kind='scatter', x='volatility',\n","                      y='returns', c='sharpe_ratio',\n","                      cmap='RdYlGn', edgecolors='black',\n","                      ax=ax)\n","ax.set(xlabel='Volatility',\n","       ylabel='Expected Returns',\n","       title='Efficient Frontier')\n","ax.plot(portf_vol_ef, portf_rtns_ef, 'b--')\n","for asset_index in range(n_assets):\n","    ax.scatter(x=np.sqrt(cov_mat.iloc[asset_index, asset_index]),\n","                y=avg_returns[asset_index],\n","                #marker=MARKS[asset_index],\n","                s=150,\n","                color='black',\n","                label=RISKY_ASSETS[asset_index])\n","ax.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"UfCS6xzuOgsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_sharpe_ind = np.argmax(portf_results_df.sharpe_ratio)\n","max_sharpe_portf = portf_results_df.loc[max_sharpe_ind]\n","\n","min_vol_ind = np.argmin(portf_results_df.volatility)\n","min_vol_portf = portf_results_df.loc[min_vol_ind]"],"metadata":{"id":"pDV9uESPOgqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Maximum Sharpe Ratio portfolio ----')\n","print('Performance')\n","for index, value in max_sharpe_portf.items():\n","    print(f'{index}: {100 * value:.2f}% ', end=\"\", flush=True)\n","print('\\nWeights')\n","for x, y in zip(RISKY_ASSETS, weights[np.argmax(portf_results_df.sharpe_ratio)]):\n","    print(f'{x}: {100*y:.2f}% ', end=\"\", flush=True)"],"metadata":{"id":"88cOAWwYOgnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Minimum Volatility portfolio ----')\n","print('Performance')\n","for index, value in min_vol_portf.items():\n","    print(f'{index}: {100 * value:.2f}% ', end=\"\", flush=True)\n","print('\\nWeights')\n","for x, y in zip(RISKY_ASSETS, weights[np.argmin(portf_results_df.volatility)]):\n","    print(f'{x}: {100*y:.2f}% ', end=\"\", flush=True)"],"metadata":{"id":"cAQjw5V-Ogl6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots()\n","portf_results_df.plot(kind='scatter', x='volatility',\n","                      y='returns', c='sharpe_ratio',\n","                      cmap='RdYlGn', edgecolors='black',\n","                      ax=ax)\n","ax.scatter(x=max_sharpe_portf.volatility,\n","           y=max_sharpe_portf.returns,\n","           c='black', marker='*',\n","           s=200, label='Max Sharpe Ratio')\n","ax.scatter(x=min_vol_portf.volatility,\n","           y=min_vol_portf.returns,\n","           c='black', marker='P',\n","           s=200, label='Minimum Volatility')\n","ax.set(xlabel='Volatility', ylabel='Expected Returns',\n","       title='Efficient Frontier')\n","ax.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Om7S7uaOOgkB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KCyugwJsOgiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xpItwnkcOggN"},"execution_count":null,"outputs":[]}]}